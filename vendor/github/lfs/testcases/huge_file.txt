 which all the file writes are written sequentially in a log-like structure.  A log consists of a series of segments where each segment contains both data and inode blocks. A log structured file system gathers a segment worth of data in memory and appends the segment at the end of the log. This improves the write performance while maintaining the same read performance. Since the log is sequential in nature it helps in crash recovery as less check pointing information need to be stored. As segment can have both inode blocks and data blocks, so to keep track of all the inodes in the log we maintain an IFILE (inode map) within the log that maps all the inodes in the log. Whenever we write a segment at the end of the log, the corresponding inodes are also updated to point to the new block instead of the old block and the old block is now marked as free.
As more and more updates are done to the file system, holes (dead data) are created in the file system. A program called cleaner is required to reclaim these holes and compact the live data (inode mapped data). This can be done in two ways, threading and copying (segment compaction). In a threaded log, live data is left in place and special data structures are used to thread the log through free extents. The second approach is to compact the live data to create large free extents. Threaded log still has the problem of fragmentation, so we use a combination of both threading and copying.  Segment compaction is a three step process. First, we read few segments into the memory and identify the live data in the segments using segment summary (maintained for every segment). Prepare new segments containing only the live data and write these at the end of the log. The segments that are copied into memory are marked as free and these can be used for future writes. We use threading to identify the free segments. 
The project will be implemented on JOS.
which all the file writes are written sequentially in a log-like structure.  A log consists of a series of segments where each segment contains both data and inode blocks. A log structured file system gathers a segment worth of data in memory and appends the segment at the end of the log. This improves the write performance while maintaining the same read performance. Since the log is sequential in nature it helps in crash recovery as less check pointing information need to be stored. As segment can have both inode blocks and data blocks, so to keep track of all the inodes in the log we maintain an IFILE (inode map) within the log that maps all the inodes in the log. Whenever we write a segment at the end of the log, the corresponding inodes are also updated to point to the new block instead of the old block and the old block is now marked as free.
As more and more updates are done to the file system, holes (dead data) are created in the file system. A program called cleaner is required to reclaim these holes and compact the live data (inode mapped data). This can be done in two ways, threading and copying (segment compaction). In a threaded log, live data is left in place and special data structures are used to thread the log through free extents. The second approach is to compact the live data to create large free extents. Threaded log still has the problem of fragmentation, so we use a combination of both threading and copying.  Segment compaction is a three step process. First, we read few segments into the memory and identify the live data in the segments using segment summary (maintained for every segment). Prepare new segments containing only the live data and write these at the end of the log. The segments that are copied into memory are marked as free and these can be used for future writes. We use threading to identify the free segments. 
The project will be implemented on JOS.
which all the file writes are written sequentially in a log-like structure.  A log consists of a series of segments where each segment contains both data and inode blocks. A log structured file system gathers a segment worth of data in memory and appends the segment at the end of the log. This improves the write performance while maintaining the same read performance. Since the log is sequential in nature it helps in crash recovery as less check pointing information need to be stored. As segment can have both inode blocks and data blocks, so to keep track of all the inodes in the log we maintain an IFILE (inode map) within the log that maps all the inodes in the log. Whenever we write a segment at the end of the log, the corresponding inodes are also updated to point to the new block instead of the old block and the old block is now marked as free.
As more and more updates are done to the file system, holes (dead data) are created in the file system. A program called cleaner is required to reclaim these holes and compact the live data (inode mapped data). This can be done in two ways, threading and copying (segment compaction). In a threaded log, live data is left in place and special data structures are used to thread the log through free extents. The second approach is to compact the live data to create large free extents. Threaded log still has the problem of fragmentation, so we use a combination of both threading and copying.  Segment compaction is a three step process. First, we read few segments into the memory and identify the live data in the segments using segment summary (maintained for every segment). Prepare new segments containing only the live data and write these at the end of the log. The segments that are copied into memory are marked as free and these can be used for future writes. We use threading to identify the free segments. 
The project will be implemented on JOS.
which all the file writes are written sequentially in a log-like structure.  A log consists of a series of segments where each segment contains both data and inode blocks. A log structured file system gathers a segment worth of data in memory and appends the segment at the end of the log. This improves the write performance while maintaining the same read performance. Since the log is sequential in nature it helps in crash recovery as less check pointing information need to be stored. As segment can have both inode blocks and data blocks, so to keep track of all the inodes in the log we maintain an IFILE (inode map) within the log that maps all the inodes in the log. Whenever we write a segment at the end of the log, the corresponding inodes are also updated to point to the new block instead of the old block and the old block is now marked as free.
As more and more updates are done to the file system, holes (dead data) are created in the file system. A program called cleaner is required to reclaim these holes and compact the live data (inode mapped data). This can be done in two ways, threading and copying (segment compaction). In a threaded log, live data is left in place and special data structures are used to thread the log through free extents. The second approach is to compact the live data to create large free extents. Threaded log still has the problem of fragmentation, so we use a combination of both threading and copying.  Segment compaction is a three step process. First, we read few segments into the memory and identify the live data in the segments using segment summary (maintained for every segment). Prepare new segments containing only the live data and write these at the end of the log. The segments that are copied into memory are marked as free and these can be used for future writes. We use threading to identify the free segments. 
The project will be implemented on JOS.
which all the file writes are written sequentially in a log-like structure.  A log consists of a series of segments where each segment contains both data and inode blocks. A log structured file system gathers a segment worth of data in memory and appends the segment at the end of the log. This improves the write performance while maintaining the same read performance. Since the log is sequential in nature it helps in crash recovery as less check pointing information need to be stored. As segment can have both inode blocks and data blocks, so to keep track of all the inodes in the log we maintain an IFILE (inode map) within the log that maps all the inodes in the log. Whenever we write a segment at the end of the log, the corresponding inodes are also updated to point to the new block instead of the old block and the old block is now marked as free.
As more and more updates are done to the file system, holes (dead data) are created in the file system. A program called cleaner is required to reclaim these holes and compact the live data (inode mapped data). This can be done in two ways, threading and copying (segment compaction). In a threaded log, live data is left in place and special data structures are used to thread the log through free extents. The second approach is to compact the live data to create large free extents. Threaded log still has the problem of fragmentation, so we use a combination of both threading and copying.  Segment compaction is a three step process. First, we read few segments into the memory and identify the live data in the segments using segment summary (maintained for every segment). Prepare new segments containing only the live data and write these at the end of the log. The segments that are copied into memory are marked as free and these can be used for future writes. We use threading to identify the free segments. 
The project will be implemented on JOS.
As more and more updates are done to the file system, holes (dead data) are created in the file system. A program called cleaner is required to reclaim these holes and compact the live data (inode mapped data). This can be done in two ways, threading and copying (segment compaction). In a threaded log, live data is left in place and special data structures are used to thread the log through free extents. The second approach is to compact the live data to create large free extents. Threaded log still has the problem of fragmentation, so we use a combination of both threading and copying.  Segment compaction is a three step process. First, we read few segments into the memory and identify the live data in the segments using segment summary (maintained for every segment). Prepare new segments containing only the live data and write these at the end of the log. The segments that are copied into memory are marked as free and these can be used for future writes. We use threading to identify the free segments. 
The project will be implemented on JOS.
which all the file writes are written sequentially in a log-like structure.  A log consists of a series of segments where each segment contains both data and inode blocks. A log structured file system gathers a segment worth of data in memory and appends the segment at the end of the log. This improves the write performance while maintaining the same read performance. Since the log is sequential in nature it helps in crash recovery as less check pointing information need to be stored. As segment can have both inode blocks and data blocks, so to keep track of all the inodes in the log we maintain an IFILE (inode map) within the log that maps all the inodes in the log. Whenever we write a segment at the end of the log, the corresponding inodes are also updated to point to the new block instead of the old block and the old block is now marked as free.
As more and more updates are done to the file system, holes (dead data) are created in the file system. A program called cleaner is required to reclaim these holes and compact the live data (inode mapped data). This can be done in two ways, threading and copying (segment compaction). In a threaded log, live data is left in place and special data structures are used to thread the log through free extents. The second approach is to compact the live data to create large free extents. Threaded log still has the problem of fragmentation, so we use a combination of both threading and copying.  Segment compaction is a three step process. First, we read few segments into the memory and identify the live data in the segments using segment summary (maintained for every segment). Prepare new segments containing only the live data and write these at the end of the log. The segments that are copied into memory are marked as free and these can be used for future writes. We use threading to identify the free segments. 
The project will be implemented on JOS


